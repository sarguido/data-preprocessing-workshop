{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### What is feature selection?\n",
    "\n",
    "Feature selection is a method of selecting features from your feature set to be used for modeling. It draws from a set of existing features, so it's different than feature engineering because it doesn't create new features. The goal of feature selection is to improve your model's performance. Perhaps your existing feature set is much too large, or some of the features you're working with are unnecessary.\n",
    "\n",
    "There are different ways you can perform feature selection. It's possible to do it in an automated way. Scikit-learn has several methods for automated feature selection, such as choosing a variance threshold and using univariate statistical tests, but we won't cover those here. \n",
    "\n",
    "Feature selection can help to get rid of noise in your model. Perhaps you have redundant features, like latitude and longitude, city, and state. Or maybe you have features that are strongly statistically correlated, which breaks the assumptions of certain models and thus impacts model performance. If your feature set is large, it may be beneficial to use dimensionality reduction to combine and reduce the number of features in your dataset in a way that also reduces the overall variance.\n",
    "\n",
    "### Removing features manually\n",
    "\n",
    "One of the easiest ways to determine if a feature is unnecessary is if it is redundant in some way. For example, if it exists in another form as another featureâ€”sometimes, when you create features through feature engineering, you end up duplicating existing features in some way. \n",
    "\n",
    "For example, if your dataset contains repeated information in its feature set, it's unlikely you'll need to use each feature for modeling. You may see columns related to city, state, latitude, and longitude in the same dataset, such as in the `volunteer` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opportunity_id', 'content_id', 'vol_requests', 'event_time', 'title',\n",
       "       'hits', 'summary', 'is_priority', 'category_id', 'category_desc',\n",
       "       'amsl', 'amsl_unit', 'org_title', 'org_content_id', 'addresses_count',\n",
       "       'locality', 'region', 'postalcode', 'primary_loc', 'display_url',\n",
       "       'recurrence_type', 'hours', 'created_date', 'last_modified_date',\n",
       "       'start_date_date', 'end_date_date', 'status', 'Latitude', 'Longitude',\n",
       "       'Community Board', 'Community Council ', 'Census Tract', 'BIN', 'BBL',\n",
       "       'NTA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir_string = \"../../datasets/\"\n",
    "\n",
    "volunteer = pd.read_csv(dir_string + \"volunteer.csv\")\n",
    "volunteer.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `volunteer` dataset contains a lot of different information related to the location of the volunteer opportunity: `Latitude`, `Longitude`, `locality`, `region`, and `postalcode`.\n",
    "\n",
    "Dropping columns is as simple as using pandas' `drop()` method, which we learned about previously, but it's important to remember here. Specifying `axis=1` ensures that we drop entire columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['opportunity_id', 'content_id', 'vol_requests', 'event_time', 'title',\n",
      "       'hits', 'summary', 'is_priority', 'category_id', 'category_desc',\n",
      "       'amsl', 'amsl_unit', 'org_title', 'org_content_id', 'addresses_count',\n",
      "       'region', 'primary_loc', 'display_url', 'recurrence_type', 'hours',\n",
      "       'created_date', 'last_modified_date', 'start_date_date',\n",
      "       'end_date_date', 'status', 'Community Board', 'Community Council ',\n",
      "       'Census Tract', 'BIN', 'BBL', 'NTA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "volunteer_subset = volunteer.drop([\"Latitude\", \"Longitude\", \"locality\", \"postalcode\"], axis=1)\n",
    "\n",
    "print(volunteer_subset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, for your modeling task, you only need the high-level state information in the `region` field, which we didn't drop. \n",
    "\n",
    "Another situation where duplicate features occur is through feature engineering. In an earlier example, we calculated a number of aggregate statistics on running times. The columns we had were times from 5 separate runs as well as mean, median, total, and fastest time. We could likely drop the values that generated the aggregate statistic. Feature selection, like most aspects of the machine learning pipeline, is very dependent on the model you're trying to build.\n",
    "\n",
    "### Removing correlated features\n",
    "\n",
    "Another clear situation in which you'd want to drop features is when they are statistically correlated, meaning they move together directionally. Linear models in particular assume that features are independent of each other, and if features are strongly correlated, that could introduce bias into your model. \n",
    "\n",
    "We'll use Pearson's correlation coefficient to check a feature set for correlation. The Pearson correlation coefficient is a measure of this directionality: a score closer to 1 between pairs of features means that they move together in the same direction more strongly, a score closer to 0 means features are not correlated, and a score close to -1 means they are more strongly negatively correlated, meaning one feature increases in value while the other decreases. \n",
    "\n",
    "Let's take a look at this simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = {\"col1\": [1, 2, 3, 4], \n",
    "             \"col2\": [0.23, 3, 8, -9], \n",
    "             \"col3\": [10, 20, 30, 40], \n",
    "             \"col4\": [0.3, 0.2, 90.6, 0.1]}\n",
    "\n",
    "corr_df = pd.DataFrame(corr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check correlation in Pandas using the `corr()` method, which outputs features and their measures of correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>col1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.410435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col2</th>\n",
       "      <td>-0.410435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.410435</td>\n",
       "      <td>0.696157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.410435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col4</th>\n",
       "      <td>0.256485</td>\n",
       "      <td>0.696157</td>\n",
       "      <td>0.256485</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          col1      col2      col3      col4\n",
       "col1  1.000000 -0.410435  1.000000  0.256485\n",
       "col2 -0.410435  1.000000 -0.410435  0.696157\n",
       "col3  1.000000 -0.410435  1.000000  0.256485\n",
       "col4  0.256485  0.696157  0.256485  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, every column is obviously perfectly correlated with itself. However, we can also see that colunms 1 and 3 have a perfect correlation as well! In the toy dataset above, you can see that column 3 is simply column 1 multipled by 10, so this makes sense. We'd definitely want to remove one of those columns.\n",
    "\n",
    "Correlation isn't usually as clear-cut as this. You can also see that columns 2 and 4 have a relatively high correlation at around 0.7. Since there are only four features in this dataset, perhaps we wouldn't remove one of those columns. This is where iteration is important - you might be able to pick the perfect feature set on the first try, or you might need to experiment with a few different configurations.\n",
    "\n",
    "### Your turn!\n",
    "\n",
    "Let's take a look at the `wine` dataset, which is made up of continuous, numerical features of various characteristics of wine. Read in the file and print out the `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0     1    14.23        1.71  2.43               15.6        127   \n",
       "1     1    13.20        1.78  2.14               11.2        100   \n",
       "2     1    13.16        2.36  2.67               18.6        101   \n",
       "3     1    14.37        1.95  2.50               16.8        113   \n",
       "4     1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(dir_string + \"wine_types.csv\")\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a subset of the `wine` dataset so we can see the output of `corr()` more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.543479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>0.864564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.433681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>-0.411007</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.561296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Flavanoids  Total phenols  Malic acid  \\\n",
       "Flavanoids                      1.000000       0.864564   -0.411007   \n",
       "Total phenols                   0.864564       1.000000   -0.335167   \n",
       "Malic acid                     -0.411007      -0.335167    1.000000   \n",
       "OD280/OD315 of diluted wines    0.787194       0.699949   -0.368710   \n",
       "Hue                             0.543479       0.433681   -0.561296   \n",
       "\n",
       "                              OD280/OD315 of diluted wines       Hue  \n",
       "Flavanoids                                        0.787194  0.543479  \n",
       "Total phenols                                     0.699949  0.433681  \n",
       "Malic acid                                       -0.368710 -0.561296  \n",
       "OD280/OD315 of diluted wines                      1.000000  0.565468  \n",
       "Hue                                               0.565468  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_subset = wine[[\"Flavanoids\", \"Total phenols\", \"Malic acid\", \"OD280/OD315 of diluted wines\", \"Hue\"]]\n",
    "\n",
    "wine_subset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a close look at the `Flavanoids` feature after correlation, you can see that it's strongly positively correlated with both `Total phenols` and `OD280/OD315 of diluted wines`. Let's drop it from that subset, and then look at the correlation again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.433681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>-0.335167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.561296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Total phenols  Malic acid  \\\n",
       "Total phenols                      1.000000   -0.335167   \n",
       "Malic acid                        -0.335167    1.000000   \n",
       "OD280/OD315 of diluted wines       0.699949   -0.368710   \n",
       "Hue                                0.433681   -0.561296   \n",
       "\n",
       "                              OD280/OD315 of diluted wines       Hue  \n",
       "Total phenols                                     0.699949  0.433681  \n",
       "Malic acid                                       -0.368710 -0.561296  \n",
       "OD280/OD315 of diluted wines                      1.000000  0.565468  \n",
       "Hue                                               0.565468  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_subset = wine_subset.drop(\"Flavanoids\", axis=1)\n",
    "\n",
    "wine_subset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature you might consider dropping is `OD280/OD315 of diluted wines`, which is strongly positively correlated with `Total Phenols` and moderately positively correlated with `Hue`. This is a situation where you'd want to iterate on your chosen features and see how they impact your model's performance.\n",
    "\n",
    "### Dimensionality reduction for feature selection\n",
    "\n",
    "A less manual way of reducing the size of your feature set is through dimensionality reduction. Dimensionality reduction is a form of unsupervised learning that transforms your data in a way that shrinks the number of features in your feature space. \n",
    "\n",
    "The method of dimensionality reduction we'll cover is principal component analysis, or PCA. PCA uses a linear transformation to project features into a space where they are completely uncorrelated. While the feature space is reduced, the variance is captured in a meaningful way by combining features into components. PCA captures, in each component, as much of the variance in the dataset as possible. In terms of feature selection, it can be a useful method when you have a large number of features and no strong candidates for elimination.\n",
    "\n",
    "Transforming a dataset through PCA is relatively straightforward in scikit-learn. Let's apply PCA to the `wine` dataset. \n",
    "\n",
    "First, we'll set up our data for modeling by removing the label column, `Type`, from the `wine` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_X = wine.drop([\"Type\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll apply `PCA` to `wine_X` using `fit_transform()`, which transforms the data into components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "transformed_X = pca.fit_transform(wine_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, PCA in scikit-learn keeps the number of components equal to the number of input features. If we print out the `explained_variance_ratio_`, we can see, by component, the percentage of variance explained by that component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.98091230e-01, 1.73591562e-03, 9.49589576e-05, 5.02173562e-05,\n",
       "       1.23636847e-05, 8.46213034e-06, 2.80681456e-06, 1.52308053e-06,\n",
       "       1.12783044e-06, 7.21415811e-07, 3.78060267e-07, 2.12013755e-07,\n",
       "       8.25392788e-08])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that much of the variance is explained by the first component hereâ€”around 99%â€”so it's likely that we could drop those components that don't explain much variance.\n",
    "\n",
    "There are a couple of things to note regarding PCA. The first is that it can be very difficult to interpret PCA components beyond which components explain the most variance. PCA is more of a black box method than other methods of dimensionality reduction. The other thing to note is that PCA is a good step to do at the end of your preprocessing journey, because of the way the data gets transformed and reshaped. It can be difficult to do much feature work post-PCA, other than eliminating components that aren't useful in explaining variance.\n",
    "\n",
    "### Your turn: training a model using PCA\n",
    "\n",
    "Let's take a look at how `knn` performs using PCA components as the `X` data. First, let's create our `y` labels out of the `Type` column as well as split the PCA-transformed data. We can simply pass in the `transformed_X` data we created in the previous step to `train_test_split()` to create training and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = wine[\"Type\"]\n",
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(transformed_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the `knn` classifier, fit it to the training data, and score it on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_pca = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model to the data and print out the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555555555555555"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pca.fit(X_pca_train, y_pca_train)\n",
    "\n",
    "knn_pca.score(X_pca_test, y_pca_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to think about: What other improvements could you make to the `wine` dataset? Would you use PCA? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
