{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### What is feature selection?\n",
    "\n",
    "Feature selection is a method of selecting features from your feature set to be used for modeling. It draws from a set of existing features, so it's different than feature engineering because it doesn't create new features. The goal of feature selection is to improve your model's performance. Perhaps your existing feature set is much too large, or some of the features you're working with are unnecessary.\n",
    "\n",
    "### Removing features manually\n",
    "\n",
    "One of the easiest ways to determine if a feature is unnecessary is if it is redundant in some way. For example, if it exists in another form as another feature—sometimes, when you create features through feature engineering, you end up duplicating existing features in some way. \n",
    "\n",
    "For example, if your dataset contains repeated information in its feature set, it's unlikely you'll need to use each feature for modeling. You may see columns related to city, state, latitude, and longitude in the same dataset, such as in the `volunteer` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opportunity_id', 'content_id', 'vol_requests', 'event_time', 'title',\n",
       "       'hits', 'summary', 'is_priority', 'category_id', 'category_desc',\n",
       "       'amsl', 'amsl_unit', 'org_title', 'org_content_id', 'addresses_count',\n",
       "       'locality', 'region', 'postalcode', 'primary_loc', 'display_url',\n",
       "       'recurrence_type', 'hours', 'created_date', 'last_modified_date',\n",
       "       'start_date_date', 'end_date_date', 'status', 'Latitude', 'Longitude',\n",
       "       'Community Board', 'Community Council ', 'Census Tract', 'BIN', 'BBL',\n",
       "       'NTA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir_string = \"../../datasets/\"\n",
    "\n",
    "volunteer = pd.read_csv(dir_string + \"volunteer.csv\")\n",
    "volunteer.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `volunteer` dataset contains a lot of different information related to the location of the volunteer opportunity: `Latitude`, `Longitude`, `locality`, `region`, and `postalcode`.\n",
    "\n",
    "Dropping columns is as simple as using pandas' `drop()` method, which we learned about previously, but it's important to remember here. Specifying `axis=1` ensures that we drop entire columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['opportunity_id', 'content_id', 'vol_requests', 'event_time', 'title',\n",
      "       'hits', 'summary', 'is_priority', 'category_id', 'category_desc',\n",
      "       'amsl', 'amsl_unit', 'org_title', 'org_content_id', 'addresses_count',\n",
      "       'region', 'primary_loc', 'display_url', 'recurrence_type', 'hours',\n",
      "       'created_date', 'last_modified_date', 'start_date_date',\n",
      "       'end_date_date', 'status', 'Community Board', 'Community Council ',\n",
      "       'Census Tract', 'BIN', 'BBL', 'NTA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "volunteer_subset = volunteer.drop([\"Latitude\", \"Longitude\", \"locality\", \"postalcode\"], axis=1)\n",
    "\n",
    "print(volunteer_subset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, for your modeling task, you only need the high-level state information in the `region` field, which we didn't drop. \n",
    "\n",
    "Another situation where duplicate features occur is through feature engineering. In an earlier example, we took an average on running times from a group of people to use as an aggregate statistic. It's likely that we could drop the values that generated the aggregate statistic. It's very dependent on the model you're trying to build.\n",
    "\n",
    "### Removing correlated features\n",
    "\n",
    "Another clear situation in which you'd want to drop features is when they are statistically correlated, meaning they move together directionally. Linear models in particular assume that features are independent of each other, and if features are strongly correlated, that could introduce bias into your model. \n",
    "\n",
    "We'll use Pearson's correlation coefficient to check a feature set for correlation. The Pearson correlation coefficient is a measure of this directionality: a score closer to 1 between pairs of features means that they move together in the same direction more strongly, a score closer to 0 means features are not correlated, and a score close to -1 means they are more strongly negatively correlated, meaning one feature increases in value while the other decreases. \n",
    "\n",
    "Let's take a look at the `wine` dataset, which is made up of continuous, numerical features of various characteristics of wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0     1    14.23        1.71  2.43               15.6        127   \n",
       "1     1    13.20        1.78  2.14               11.2        100   \n",
       "2     1    13.16        2.36  2.67               18.6        101   \n",
       "3     1    14.37        1.95  2.50               16.8        113   \n",
       "4     1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(dir_string + \"wine_types.csv\")\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check correlation in pandas using the `corr()` method, which outputs features and their measures of correlation. Let's use a subset of the `wine` dataset so we can see the output more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.543479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>0.864564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.433681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>-0.411007</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.561296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Flavanoids  Total phenols  Malic acid  \\\n",
       "Flavanoids                      1.000000       0.864564   -0.411007   \n",
       "Total phenols                   0.864564       1.000000   -0.335167   \n",
       "Malic acid                     -0.411007      -0.335167    1.000000   \n",
       "OD280/OD315 of diluted wines    0.787194       0.699949   -0.368710   \n",
       "Hue                             0.543479       0.433681   -0.561296   \n",
       "\n",
       "                              OD280/OD315 of diluted wines       Hue  \n",
       "Flavanoids                                        0.787194  0.543479  \n",
       "Total phenols                                     0.699949  0.433681  \n",
       "Malic acid                                       -0.368710 -0.561296  \n",
       "OD280/OD315 of diluted wines                      1.000000  0.565468  \n",
       "Hue                                               0.565468  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_subset = wine[[\"Flavanoids\", \"Total phenols\", \"Malic acid\", \"OD280/OD315 of diluted wines\", \"Hue\"]]\n",
    "\n",
    "wine_subset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a close look at the `Flavanoids` feature after correlation, you can see that it's strongly positively correlated with both `Total phenols` and `OD280/OD315 of diluted wines`. Let's drop it from that subset, and then look at the correlation again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.433681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>-0.335167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.561296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Total phenols  Malic acid  \\\n",
       "Total phenols                      1.000000   -0.335167   \n",
       "Malic acid                        -0.335167    1.000000   \n",
       "OD280/OD315 of diluted wines       0.699949   -0.368710   \n",
       "Hue                                0.433681   -0.561296   \n",
       "\n",
       "                              OD280/OD315 of diluted wines       Hue  \n",
       "Total phenols                                     0.699949  0.433681  \n",
       "Malic acid                                       -0.368710 -0.561296  \n",
       "OD280/OD315 of diluted wines                      1.000000  0.565468  \n",
       "Hue                                               0.565468  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_subset = wine_subset.drop(\"Flavanoids\", axis=1)\n",
    "\n",
    "wine_subset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature you might consider dropping is `OD280/OD315 of diluted wines`, which is strongly positively correlated with `Total Phenols` and moderately positively correlated with `Hue`. This is a situation where you'd want to iterate on your chosen features and see how they impact your model's performance.\n",
    "\n",
    "### Dimensionality reduction for feature selection\n",
    "\n",
    "A less manual way of reducing the size of your feature set is through dimensionality reduction. Dimensionality reduction is a form of unsupervised learning that transforms your data in a way that shrinks the number of features in your feature space. \n",
    "\n",
    "The method of dimensionality reduction we'll cover is principal component analysis, or PCA. PCA uses a linear transformation to project features into a space where they are completely uncorrelated. While the feature space is reduced, the variance is captured in a meaningful way by combining features into components. PCA captures, in each component, as much of the variance in the dataset as possible. In terms of feature selection, it can be a useful method when you have a large number of features and no strong candidates for elimination.\n",
    "\n",
    "Transforming a dataset through PCA is relatively straightforward in scikit-learn. Let's apply PCA to the `wine` dataset, to see if we can get an increase in our model's accuracy. \n",
    "\n",
    "First, we'll set up our data for modeling by removing the label column, `Type`, from the `wine` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_X = wine.drop(\"Type\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll apply `PCA` to `wine_X` using `fit_transform()`, which transforms the data into components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "transformed_X = pca.fit_transform(wine_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, PCA in scikit-learn keeps the number of components equal to the number of input features. If we print out the explained variance ratio, we can see, by component, the percentage of variance explained by that component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.98091230e-01, 1.73591562e-03, 9.49589576e-05, 5.02173562e-05,\n",
       "       1.23636847e-05, 8.46213034e-06, 2.80681456e-06, 1.52308053e-06,\n",
       "       1.12783044e-06, 7.21415811e-07, 3.78060267e-07, 2.12013755e-07,\n",
       "       8.25392788e-08])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that much of the variance is explained by the first component here—around 99%—so it's likely that we could drop those components that don't explain much variance.\n",
    "\n",
    "There are a couple of things to note regarding PCA. The first is that it can be very difficult to interpret PCA components beyond which components explain the most variance. PCA is more of a black box method than other methods of dimensionality reduction. The other thing to note is that PCA is a good step to do at the end of your preprocessing journey, because of the way the data gets transformed and reshaped. It can be difficult to do much feature work post-PCA, other than eliminating components that aren't useful in explaining variance.\n",
    "\n",
    "### Training a model using PCA\n",
    "\n",
    "Let's look at training a model both with the components from PCA, as well as without, to compare model performance.\n",
    "\n",
    "Let's first see how modeling without PCA performs. We'll use a basic k-nearest neighboors model to see if we can predict the wine `Type` from its other features. First, let's set up the data. We'll split the non-transformed data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = wine[\"Type\"]\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(wine_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the `knn` classifier, fit it to the training data, and score it on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_wine_train, y_wine_train)\n",
    "\n",
    "print(knn.score(X_wine_test, y_wine_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it doesn't perform that badly without PCA. \n",
    "\n",
    "Let's take a look at how `knn` performs using PCA components as the `X` data. We can simply pass in the `transformed_X` data we created in the previous step to `train_test_split()` to create training and test data. We'll also create a new `knn` model to use on the component data, and then print out the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(transformed_X, y)\n",
    "\n",
    "knn_pca = KNeighborsClassifier()\n",
    "knn_pca.fit(X_pca_train, y_pca_train)\n",
    "\n",
    "print(knn_pca.score(X_pca_test, y_pca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's likely an improvement, without doing any other feature selection. We could definitely remove correlated features, or even scale the data, before transforming the data via PCA to get additional modeling improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
